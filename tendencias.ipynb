{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo recuperado\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('incidentes_training.pkl'):\n",
    "    print('Archivo recuperado')\n",
    "    df_copy = pd.read_pickle('incidentes_training.pkl')\n",
    "else:\n",
    "    print('Archivo no encontrado')\n",
    "    df_copy = pd.read_excel('compilado_delitos_2022.xlsx', dtype=str)\n",
    "    df_copy.to_pickle('incidentes_training.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(349804, 42)\n",
      "Index(['folio', 'origen_incidente', 'fecha_creacion', 'hora_creacion',\n",
      "       'dia_semana', 'fecha_cierre', 'hora_cierre', 'usuario_inicia',\n",
      "       'existe_video', 'numero_llamante', 'nombre_llamante',\n",
      "       'numero_alternativo', 'incidente_c4', 'tipo_intervencion_c2', 'calle',\n",
      "       'numero', 'esquina', 'colonia', 'codigo_postal', 'delegacion_inicio',\n",
      "       'sector_inicio', 'c2_inicio', 'latitud', 'longitud', 'senias',\n",
      "       'codigo_cierre', 'comentarios', 'detenidos', 'tiempo_resp_fce',\n",
      "       'clas_con_f_alarma', 'tipo_entrada', 'delegacion_cierre',\n",
      "       'sector_cierre', 'c2_cierre', 'usuario_cierre', 'usuario_intervencion',\n",
      "       'folio_padre', 't_aten_066', 't_desp_c2_c4', 't_unidad', 't_total',\n",
      "       'inc-clas'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = df_copy.copy()\n",
    "#Print dimensions of the dataset\n",
    "print(df.shape)# Print columns of the dataset\n",
    "print(df.columns)\n",
    "# Print the first 5 rows of the data\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha_creacion</th>\n",
       "      <th>hora_creacion</th>\n",
       "      <th>mes_creacion</th>\n",
       "      <th>dia_creacion</th>\n",
       "      <th>semana_creacion</th>\n",
       "      <th>dia_semana</th>\n",
       "      <th>incidente_c4</th>\n",
       "      <th>colonia</th>\n",
       "      <th>delegacion_inicio</th>\n",
       "      <th>sector_inicio</th>\n",
       "      <th>latitud</th>\n",
       "      <th>longitud</th>\n",
       "      <th>codigo_cierre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-02</td>\n",
       "      <td>07:00</td>\n",
       "      <td>04-Abril</td>\n",
       "      <td>02</td>\n",
       "      <td>13</td>\n",
       "      <td>6-Sábado</td>\n",
       "      <td>Robo-Vehículo sin Violencia</td>\n",
       "      <td>ZONA ESCOLAR</td>\n",
       "      <td>GUSTAVO A. MADERO</td>\n",
       "      <td>CUAUTEPEC</td>\n",
       "      <td>19.540726</td>\n",
       "      <td>-99.1446619</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-04-07</td>\n",
       "      <td>22:00</td>\n",
       "      <td>04-Abril</td>\n",
       "      <td>07</td>\n",
       "      <td>14</td>\n",
       "      <td>4-Jueves</td>\n",
       "      <td>Robo-Vehiculo con Violencia</td>\n",
       "      <td>SAN JUAN DE ARAGON VI SECCION</td>\n",
       "      <td>GUSTAVO A. MADERO</td>\n",
       "      <td>ARAGON</td>\n",
       "      <td>19.466062</td>\n",
       "      <td>-99.064584</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-04-07</td>\n",
       "      <td>21:00</td>\n",
       "      <td>04-Abril</td>\n",
       "      <td>07</td>\n",
       "      <td>14</td>\n",
       "      <td>4-Jueves</td>\n",
       "      <td>Robo-Vehiculo con Violencia</td>\n",
       "      <td>LA PLANTA</td>\n",
       "      <td>IZTAPALAPA</td>\n",
       "      <td>TEZONCO</td>\n",
       "      <td>19.294715</td>\n",
       "      <td>-99.065944</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-04-08</td>\n",
       "      <td>11:00</td>\n",
       "      <td>04-Abril</td>\n",
       "      <td>08</td>\n",
       "      <td>14</td>\n",
       "      <td>5-Viernes</td>\n",
       "      <td>Robo-Vehículo sin Violencia</td>\n",
       "      <td>EJIDOS DE SAN PEDRO MARTIR</td>\n",
       "      <td>TLALPAN</td>\n",
       "      <td>HUIPULCO-HOSPITALES</td>\n",
       "      <td>19.264921</td>\n",
       "      <td>-99.162166</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-04-15</td>\n",
       "      <td>21:00</td>\n",
       "      <td>04-Abril</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>5-Viernes</td>\n",
       "      <td>Agresión-Persona</td>\n",
       "      <td>CENTRO (AREA 9)</td>\n",
       "      <td>CUAUHTEMOC</td>\n",
       "      <td>CENTRO</td>\n",
       "      <td>19.42481</td>\n",
       "      <td>-99.132952</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fecha_creacion hora_creacion mes_creacion dia_creacion  semana_creacion  \\\n",
       "0     2022-04-02         07:00     04-Abril           02               13   \n",
       "2     2022-04-07         22:00     04-Abril           07               14   \n",
       "3     2022-04-07         21:00     04-Abril           07               14   \n",
       "4     2022-04-08         11:00     04-Abril           08               14   \n",
       "6     2022-04-15         21:00     04-Abril           15               15   \n",
       "\n",
       "  dia_semana                 incidente_c4                        colonia  \\\n",
       "0   6-Sábado  Robo-Vehículo sin Violencia                   ZONA ESCOLAR   \n",
       "2   4-Jueves  Robo-Vehiculo con Violencia  SAN JUAN DE ARAGON VI SECCION   \n",
       "3   4-Jueves  Robo-Vehiculo con Violencia                      LA PLANTA   \n",
       "4  5-Viernes  Robo-Vehículo sin Violencia     EJIDOS DE SAN PEDRO MARTIR   \n",
       "6  5-Viernes             Agresión-Persona                CENTRO (AREA 9)   \n",
       "\n",
       "   delegacion_inicio        sector_inicio    latitud     longitud  \\\n",
       "0  GUSTAVO A. MADERO            CUAUTEPEC  19.540726  -99.1446619   \n",
       "2  GUSTAVO A. MADERO               ARAGON  19.466062   -99.064584   \n",
       "3         IZTAPALAPA              TEZONCO  19.294715   -99.065944   \n",
       "4            TLALPAN  HUIPULCO-HOSPITALES  19.264921   -99.162166   \n",
       "6         CUAUHTEMOC               CENTRO   19.42481   -99.132952   \n",
       "\n",
       "  codigo_cierre  \n",
       "0             A  \n",
       "2             A  \n",
       "3             A  \n",
       "4             A  \n",
       "6             A  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Save columns and drop the ones that are not needed\n",
    "       ['fecha_creacion', 'hora_creacion',\n",
    "       'dia_semana', 'incidente_c4', 'colonia', 'delegacion_inicio',\n",
    "       'sector_inicio', 'latitud', 'longitud']\n",
    "'''\n",
    "df.fillna('0', inplace=True)\n",
    "\n",
    "# solo considerar los registros que tengan \"A\" en la columna codigo_cierre\n",
    "df = df[df['codigo_cierre'] == 'A']\n",
    "\n",
    "# Remove YYYY-MM-DD in field hora_creacion\n",
    "df['hora_creacion'] = df['hora_creacion'].str[11:13]+':00'\n",
    "# Remove rows with date 2021-12-31\n",
    "df = df[df.fecha_creacion != '2021-12-31']\n",
    "df = df[df.fecha_creacion != '2023-01-01']\n",
    "# Remove YYYY of field fecha_creacion\n",
    "# df['fecha_creacion'] = df['fecha_creacion'].str[5:]\n",
    "# Map dia_semana from name to int-name\n",
    "df['dia_semana'] = df['dia_semana'].replace({'Lunes':'1-Lunes', 'Martes':'2-Martes', 'Miércoles':'3-Miércoles', 'Jueves':'4-Jueves', 'Viernes':'5-Viernes', 'Sábado':'6-Sábado', 'Domingo':'7-Domingo'})\n",
    "# Map mes_creacion from name to int-name\n",
    "df['mes_creacion'] = df['fecha_creacion'].str[5:7].replace({'01':'01-Enero', '02':'02-Febrero', '03':'03-Marzo', '04':'04-Abril', '05':'05-Mayo', '06':'06-Junio', '07':'07-Julio', '08':'08-Agosto', '09':'09-Septiembre', '10':'10-Octubre', '11':'11-Noviembre', '12':'12-Diciembre'})\n",
    "# Map dia-mes_creacion from name to int\n",
    "df['dia_creacion'] = df['fecha_creacion'].str[8:]\n",
    "# Get de week number of the year\n",
    "df['fecha_creacion'] = pd.to_datetime(df['fecha_creacion'], format='%Y-%m-%d')\n",
    "df['semana_creacion'] = df['fecha_creacion'].dt.isocalendar().week\n",
    "# Parse str to datetime\n",
    "\n",
    "\n",
    "columns = ['fecha_creacion', 'hora_creacion', 'mes_creacion', 'dia_creacion', 'semana_creacion',\n",
    "        'dia_semana', 'incidente_c4', 'colonia', 'delegacion_inicio',\n",
    "        'sector_inicio', 'latitud', 'longitud', 'codigo_cierre']\n",
    "\n",
    "df = df[columns]\n",
    "\n",
    "\n",
    "\n",
    "# Print the first 5 rows of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# diferentes codigo_cierre en el dataset\n",
    "df.codigo_cierre.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    127940\n",
       "Name: codigo_cierre, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cuantos registros hay de cada codigo_cierre\n",
    "df.codigo_cierre.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar los datos por delitos\n",
    "df_delitos = df.groupby('incidente_c4')\n",
    "# df_delitos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "# 'Estadisticas trimestrales' en ingles: 'Trimestral statistics'\n",
    "def statistic_frequency(df_main:pd.DataFrame, conditionals:list[pd.Series], groupby:str, titles:list[str], dir:str, num_high:int=5, num_low:int=5):\n",
    "\tfrom matplotlib.backends.backend_pdf import PdfPages\n",
    "\timport os\n",
    "\n",
    "\tif not os.path.exists(dir):\n",
    "\t\tos.makedirs(dir)\n",
    "\n",
    "\twith PdfPages(dir + '/'+ dir +'.pdf') as pdf:\n",
    "\t\tdf_main_by_delitos = df_main.groupby('incidente_c4')\n",
    "\t\tfor delito, delito_df in df_main_by_delitos:\n",
    "\t\t\tfig, axes = plt.subplots(nrows=1, ncols=len(conditionals), figsize=(5*len(conditionals), 5))\n",
    "\t\t\t# check if axes is a list or a single axis\n",
    "\t\t\tif not isinstance(axes, np.ndarray):\n",
    "\t\t\t\taxes = [axes]\n",
    "\n",
    "\t\t\tdf_delito_pts = [delito_df[conditional] for conditional in conditionals]\n",
    "\t\t\t\n",
    "\t\t\t\n",
    "\t\t\tfor df_section,title,axe in zip(df_delito_pts, titles, axes):\n",
    "\t\t\t\tdelito_df_pt = df_section.groupby(groupby).count()['incidente_c4']\n",
    "\t\t\n",
    "\t\t\t\tdelito_df_pt.plot(ax=axe, color='black', alpha=0.25)\n",
    "\t\t\t\taxe.set_title(title)\n",
    "\t\t\t\taxe.set_xticklabels(axe.get_xticklabels(), rotation=90)\n",
    "\n",
    "\t\t\t\t# Add scatter points with text labels to 5th hights days\n",
    "\t\t\t\tdelito_df_pt1_sorted = delito_df_pt.sort_values(ascending=False)\n",
    "\t\t\t\tfor i, (x, y) in enumerate(zip(delito_df_pt1_sorted.index, delito_df_pt1_sorted.values)):\n",
    "\t\t\t\t\tif i < num_low or i+num_high >= len(delito_df_pt1_sorted):\n",
    "\t\t\t\t\t\tx_pos = delito_df_pt.index.get_loc(x)\n",
    "\t\t\t\t\t\taxe.scatter(x_pos, y, s=10,  color='red' if i<num_low else 'green')\n",
    "\t\t\t\t\t\taxe.text(x_pos, y, str(f\"{x} [{y}]\"), fontsize=8, color='red' if i<num_low else 'green', rotation=90,  horizontalalignment='right', verticalalignment='top')\n",
    "\n",
    "\t\t\t#Get Max scale of all axes using get_ylim()\n",
    "\t\t\ty_max = max([ax.get_ylim()[1] for ax in axes])\n",
    "\t\t\t#Set all axes to the same scale\n",
    "\t\t\tfor ax in axes:\n",
    "\t\t\t\tax.set_ylim(0, y_max)\n",
    "\n",
    "\n",
    "\t\t\tplt.suptitle(delito)\n",
    "\t\t\tplt.savefig(f\"{dir}/{delito}.png\")\n",
    "\t\t\tpdf.savefig()\n",
    "\t\t\tplt.show()\n",
    "\t\tplt.close()\n",
    "\n",
    "def statistic_heatmap(df_main:pd.DataFrame, index, columns, title, dir:str):\n",
    "\timport os\n",
    "\timport seaborn as sns\n",
    "\timport matplotlib.pyplot as plt\n",
    "\tfrom matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "\tif not os.path.exists(dir):\n",
    "\t\tos.makedirs(dir)\n",
    "\n",
    "\n",
    "\twith PdfPages(f'{dir}/{dir}.pdf') as pdf:\n",
    "\t\tdf_main_by_delitos = df_main.groupby('incidente_c4')\n",
    "\t\tfor delito, delito_df in df_main_by_delitos:\n",
    "\t\t\t# Create a pivot table with the count of incidents by day and hour\n",
    "\t\t\tdelito_df_pt = delito_df.pivot_table(index=index, columns=columns, values='incidente_c4', aggfunc='count', fill_value=0)\n",
    "\t\t\t# Plot the heatmap\n",
    "\t\t\tfig, ax = plt.subplots()\n",
    "\t\t\tsns.heatmap(delito_df_pt, cmap='Spectral_r', annot=True, ax=ax, fmt='d')\n",
    "\t\t\t# plt.tick_params(axis='x', labelrotation=90, labeltop=True, labelbottom=False, labelsize=20)\n",
    "\t\t\tax.set_title(title)\n",
    "\t\t\tplt.suptitle(delito)\n",
    "\t\t\tpdf.savefig()\n",
    "\t\t\tplt.savefig(f\"{dir}/{delito}.png\")\n",
    "\t\t\tplt.show()\n",
    "\t\tplt.close()\n",
    "\n",
    "def statistic_geomap(df_main:pd.DataFrame, groupby:str, title:str, dir:str, USE_SECTORS:bool=True):\n",
    "\timport os\n",
    "\timport geopandas as gpd\n",
    "\tfrom shapely.geometry import Point\n",
    "\tfrom matplotlib.backends.backend_pdf import PdfPages\n",
    "\timport matplotlib.pyplot as plt\n",
    "\timport seaborn as sns\n",
    "\n",
    "\tif not os.path.exists(dir):\n",
    "\t\tos.makedirs(dir)\n",
    "\n",
    "\tif USE_SECTORS:\n",
    "\t\tmxcity = gpd.read_file('mapa_mexico_sectores/')\\\n",
    "\t\t\t.set_index('TERRITORIA')\\\n",
    "\t\t\t.to_crs(epsg=4326)\n",
    "\telse:\n",
    "\t\t# Obtain the map of Mexico\n",
    "\t\tmx = gpd.read_file('mapa_mexico/')\\\n",
    "\t\t\t\t.set_index('CLAVE')\\\n",
    "\t\t\t\t.to_crs(epsg=4326)\n",
    "\t\t# obtain the map of Mexico City with the geometry of the city\n",
    "\t\tmxcity = mx.query('CVE_EDO==\\\"09\\\"')\n",
    "\n",
    "\t# leer archivo xlsx de camaras in sheet 'base'\n",
    "\tdf_cameras = pd.read_excel('BASE_24ENE023.xlsx', sheet_name='BASE')\n",
    "\t# ob\n",
    "\tdf_cameras = df_cameras[['CYGW', 'CXGW']]\n",
    "\tdf_cameras = df_cameras.dropna()\n",
    "\n",
    "\t# Coordinate reference system : WGS84\n",
    "\tcrs = {'init': 'epsg:4326'}\n",
    "\n",
    "\n",
    "\twith PdfPages(f'{dir}/{dir}.pdf') as pdf:\n",
    "\t\t# Plot the cameras\n",
    "\t\tgdf_cameras = gpd.GeoDataFrame(\n",
    "\t\t\tdf_cameras,\n",
    "\t\t\tcrs=crs,\n",
    "\t\t\tgeometry=gpd.points_from_xy(df_cameras.CXGW, df_cameras.CYGW)\n",
    "\t\t)\n",
    "\t\tgdf_cameras.plot(ax=ax, markersize=2, color='blue', alpha=0.1)\n",
    "\n",
    "\t\tplt.suptitle('Camaras')\n",
    "\t\tpdf.savefig()\n",
    "\t\tplt.savefig(f\"{dir}/{delito}.png\")\n",
    "\t\tplt.show()\n",
    "\n",
    "\n",
    "\t\tdf_main_by_delitos = df_main.groupby('incidente_c4')\n",
    "\t\tfor delito, delito_df in df_main_by_delitos:\n",
    "\t\t\tfig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "\t\t\tmxcity.boundary.plot(ax=ax, color='black', linewidth=1.5)\n",
    "\t\t\t#mxcity.plot(ax=ax, color='white', edgecolor='black')\n",
    "\n",
    "\t\t\t# Create a GeoDataFrame from the DataFrame\n",
    "\t\t\tgdf = gpd.GeoDataFrame(\n",
    "\t\t\t\tdelito_df, \n",
    "\t\t\t\tcrs=crs,\n",
    "\t\t\t\tgeometry=gpd.points_from_xy(delito_df.longitud, delito_df.latitud)\n",
    "\t\t\t)\n",
    "\n",
    "\t\t\t# Plot the incidents\n",
    "\t\t\tgdf.plot(ax=ax, markersize=2, color='#26A337', alpha=0.075)\n",
    "\n",
    "\t\t\t# Add a title\n",
    "\t\t\tax.set_title(title)\n",
    "\t\t\tplt.suptitle(delito)\n",
    "\t\t\tpdf.savefig()\n",
    "\t\t\tplt.savefig(f\"{dir}/{delito}.png\")\n",
    "\t\t\tplt.show()\n",
    "\t\tplt.close()\n",
    "\n",
    "def statistic_heatgeomap(df_main:pd.DataFrame, index, columns, title, dir:str, USE_SECTORS:bool=True):\n",
    "\timport os\n",
    "\timport geopandas as gpd\n",
    "\tfrom shapely.geometry import Point\n",
    "\tfrom matplotlib.backends.backend_pdf import PdfPages\n",
    "\timport matplotlib.pyplot as plt\n",
    "\timport seaborn as sns\n",
    "\n",
    "\tif not os.path.exists(dir):\n",
    "\t\tos.makedirs(dir)\n",
    "\n",
    "\tif USE_SECTORS:\n",
    "\t\tmxcity = gpd.read_file('mapa_mexico_sectores/')\\\n",
    "\t\t\t.set_index('TERRITORIA')\\\n",
    "\t\t\t.to_crs(epsg=4326)\n",
    "\telse:\n",
    "\t\t# Obtain the map of Mexico\n",
    "\t\tmx = gpd.read_file('mapa_mexico/')\\\n",
    "\t\t\t\t.set_index('CLAVE')\\\n",
    "\t\t\t\t.to_crs(epsg=4326)\n",
    "\t\t# obtain the map of Mexico City with the geometry of the city\n",
    "\t\tmxcity = mx.query('CVE_EDO==\\\"09\\\"')\n",
    "\n",
    "\t# leer archivo csv camaras_sectoractual.csv\n",
    "\tdf_cameras = pd.read_csv('CAMARAS_SECTORACTUAL.csv', sep=',')\n",
    "\t# ob\n",
    "\tdf_cameras = df_cameras[['CYGW', 'CXGW']]\n",
    "\tdf_cameras = df_cameras.dropna()\n",
    "\n",
    "\t# Coordinate reference system : WGS84\n",
    "\tcrs = {'init': 'epsg:4326'}\n",
    "\n",
    "\n",
    "\twith PdfPages(f'{dir}/{dir}.pdf') as pdf:\n",
    "\t\tdf_main_by_delitos = df_main.groupby('incidente_c4')\n",
    "\t\tfor delito, delito_df in df_main_by_delitos:\n",
    "\t\t\tfig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "\t\t\tmxcity.boundary.plot(ax=ax, color='black', linewidth=1.5)\n",
    "\t\t\t#mxcity.plot(ax=ax, color='white', edgecolor='black')\n",
    "\n",
    "\t\t\t# Create heatmap with dataframe in mexico city\n",
    "\t\t\tsns.heatmap(\n",
    "\t\t\t\tdelito_df.pivot_table(index=index, columns=columns, aggfunc='size', fill_value=0),\n",
    "\t\t\t\tcmap='YlGnBu',\n",
    "\t\t\t\tax=ax,\n",
    "\t\t\t\tlinewidths=0.1,\n",
    "\t\t\t\tlinecolor='white',\n",
    "\t\t\t\tannot=True,\n",
    "\t\t\t\tannot_kws={\"size\": 8},\n",
    "\t\t\t\tcbar=False\n",
    "\t\t\t)\n",
    "\n",
    "\t\t\t# Add a title\n",
    "\t\t\tax.set_title(title)\n",
    "\t\t\tplt.suptitle(delito)\n",
    "\t\t\tpdf.savefig()\n",
    "\t\t\tplt.savefig(f\"{dir}/{delito}.png\")\n",
    "\t\t\tplt.show()\n",
    "\t\tplt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contextual menu to ask for activity\n",
    "def ask_for_activity():\n",
    "\tactivity = input('''\n",
    "\t\tElige una actividad:\n",
    "\t\t 1. Diagramas de frecuencia\n",
    "\t\t 2. Mapas de calor\n",
    "\t\t 3. Matrices de correlación\n",
    "\t\t 4. Matries de calor\n",
    "\t\t 5. Matries de calor por Delegación\n",
    "\t''')\n",
    "\treturn activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ask for activity\n",
    "activity = ask_for_activity()\n",
    "\n",
    "if activity == '1':\n",
    "\t# Tendencia por hora del dia\n",
    "\tstatistic_frequency(\n",
    "\t\tdf,\n",
    "\t\t[df['hora_creacion']>''],\n",
    "\t\t'hora_creacion',\n",
    "\t\t['Enero - Diciembre 2022'],\n",
    "\t\t'tendencia_diaria',\n",
    "\t\t4,6\n",
    "\t)\n",
    "\n",
    "\t# Tendencia por dia de la semana\n",
    "\tstatistic_frequency(\n",
    "\t\tdf,\n",
    "\t\t[df['incidente_c4']>''],\n",
    "\t\t'dia_semana',\n",
    "\t\t['Enero - Diciembre 2022'],\n",
    "\t\t'tendencia_semanal',\n",
    "\t\t2,2\n",
    "\t)\n",
    "\n",
    "\t## Tendencia por dia del mes\n",
    "\t# statistic_frequency(\n",
    "\t# \tdf,\n",
    "\t# \t[df['incidente_c4']>''],\n",
    "\t# \t'dia_creacion',\n",
    "\t# \t['Enero - Diciembre 2022'],\n",
    "\t# \t'tendencia_mensual',\n",
    "\t# \t5,5\n",
    "\t# )\n",
    "\n",
    "\t# Tendencia por mes del año\n",
    "\tstatistic_frequency(\n",
    "\t\tdf,\n",
    "\t\t[\n",
    "\t\t\tdf['fecha_creacion'] < '04-01',\n",
    "\t\t\t((df['fecha_creacion'] >= '04-01') & (df['fecha_creacion'] < '07-01')),\n",
    "\t\t\t((df['fecha_creacion'] >= '07-01') & (df['fecha_creacion'] < '10-01')),\n",
    "\t\t\t(df['fecha_creacion'] >= '10-01')\n",
    "\t\t], \n",
    "\t\t'fecha_creacion', \n",
    "\t\t['Enero - Marzo 2022', 'Abril - Junio 2022', 'Julio - Septiembre 2022', 'Octubre - Diciembre 2022'],\n",
    "\t\t'tendencia_trimestral',\n",
    "\t\t5, 5\n",
    "\t)\n",
    "elif activity == '3':\n",
    "\tstatistic_geomap(\n",
    "\t   df, \n",
    "\t   'incidente_c4', \n",
    "\t   'Enero - Diciembre 2022', \n",
    "\t   'geomap_anual', \n",
    "\t   True\n",
    "\t)\n",
    "elif activity == '4':\n",
    "\tstatistic_heatmap(\n",
    "\t\tdf,\n",
    "\t\t'hora_creacion',\n",
    "\t\t'dia_semana',\n",
    "\t\t'Enero - Diciembre 2022',\n",
    "\t\t'heatmap_dia_hora',\n",
    "\t)\n",
    "\tstatistic_heatmap(\n",
    "\t\tdf,\n",
    "\t\t'dia_creacion',\n",
    "\t\t'mes_creacion',\n",
    "\t\t'Enero - Diciembre 2022',\n",
    "\t\t'heatmap_mes_dia',\n",
    "\t)\n",
    "elif activity == '5':\n",
    "\t# Heatmap for each delegacion_inicio\n",
    "\tfor delegacion in df['delegacion_inicio'].unique():\n",
    "\t    statistic_heatmap(\n",
    "\t        df[df['delegacion_inicio']==delegacion],\n",
    "\t        'hora_creacion',\n",
    "\t        'dia_semana',\n",
    "\t        f'{delegacion} | Enero - Diciembre 2022',\n",
    "\t        f'heatmap_dia_hora-{delegacion}',\n",
    "\t    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#statistic_heatgeomap(\n",
    "#    df, \n",
    "#    'latitud', 'longitud',\n",
    "#    'Enero - Diciembre 2022', \n",
    "#    'geomap_heat_anual', \n",
    "#    False\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Robo-Vehículo sin Violencia', 'Robo-Vehiculo con Violencia',\n",
       "       'Agresión-Persona', 'Denuncia-Persona Sospechosa',\n",
       "       'Disturbio-Concentración de Personas', 'Disturbio-Disparos',\n",
       "       'Robo-Auto partes', 'Robo-Automovilista',\n",
       "       'Robo-Establecimiento con Violencia',\n",
       "       'Robo-Establecimiento sin Violencia', 'Robo-Transeúnte',\n",
       "       'Abandono-Vehículo'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['incidente_c4'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install playwright with only chromium with npm\n",
    "if not os.path.exists('node_modules') and not os.path.exists('node_modules/playwright'):\n",
    "\t!npm init -y\n",
    "\t!npm install playwright --save-dev\n",
    "\t!npx playwright install --with-deps chromium\n",
    "\n",
    "import time\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "# Create a heatmap for gruops of delitos\n",
    "import os\n",
    "if not os.path.exists('maps'):\n",
    "\tos.makedirs('maps')\n",
    "\n",
    "for delito in df['incidente_c4'].unique():\n",
    "    m = folium.Map(\n",
    "\t\tlocation=[19.325276250942087, -99.12435477661893],\n",
    "        zoom_start=11,\n",
    "        tiles='cartodbpositron',#'cartodbpositron'|'stamentoner'|'stamenterrain'|'stamenwatercolor'|'stamenTonerLabels'|'stamenTerrainLabels'|'stamenWatercolorLabels'|'cartodbpositronLabels'|'cartodbdark_matterLabels'|'cartodbpositronNoLabels'|'cartodbdark_matterNoLabels'\n",
    "    )\n",
    "\t\n",
    "    HeatMap(\n",
    "        data=df[df['incidente_c4']==delito][['latitud', 'longitud']].values.tolist(),\n",
    "        radius=15,\n",
    "\t\tuse_local_extrema=True,\n",
    "        max_zoom=13\n",
    "    ).add_to(m)\n",
    "\n",
    "    # open or create the folder with the name 'maps' to save the maps in html format \n",
    "    \n",
    "    # save the map to html\n",
    "    m.save(f'maps/{delito}-ule.html')\n",
    "\t# wait for the map to be saved\n",
    "\n",
    "!node screenshot_maps.js\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# la funcion de coorelacion mas perra del world\n",
    "def correlation(df, title):\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    matriz=[]\n",
    "    for delito in df:\n",
    "        fila=[]\n",
    "        for delito2 in df:\n",
    "            if delito==delito2:\n",
    "                fila.append(0)\n",
    "            else:\n",
    "                fila.append(1/(abs(delito-delito2)+1))\n",
    "        matriz.append(fila)\n",
    "\n",
    "    # graficar la matriz en un heatmap con los indices de los delitos\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.title(title, fontsize=30, fontweight='bold')\n",
    "    sns.heatmap(matriz, xticklabels=df.index, yticklabels=df.index, annot=True, cmap='Spectral_r')\n",
    "    plt.tick_params(axis='x', labelrotation=90, labeltop=True, labelbottom=False)\n",
    "    plt.show()\n",
    "    return matriz\n",
    "\n",
    "def relaciones_mayor_menor(matriz:list(list())):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlación de delitos en CDMX\n",
    "\n",
    "delitos_count=df['incidente_c4'].value_counts()\n",
    "matriz_correlacion = correlation(delitos_count, 'Correlacion entre delitos CDMX sin normalizar')\n",
    "relaciones = relaciones_mayor_menor(matriz_correlacion)\n",
    "\n",
    "# Normalización de datos, dónde 1 es el valor más alto\n",
    "delitos_count_norm=delitos_count/delitos_count.max()\n",
    "matriz_correlacion_norm = correlation(delitos_count_norm, 'Correlacion entre delitos CDMX normalizado')\n",
    "relaciones_norm = relaciones_mayor_menor(matriz_correlacion_norm)\n",
    "\n",
    "#create directory correlaciones\n",
    "if not os.path.exists('correlaciones'):\n",
    "\tos.makedirs('correlaciones')\n",
    "\n",
    "#Save it in excel\n",
    "import pandas as pd\n",
    "#join relaciones and relaciones_norm\n",
    "relaciones = [relaciones[i]+relaciones_norm[i] for i in range(len(relaciones))]\n",
    "df_cor = pd.DataFrame(relaciones, columns = ['Delito 1', 'Delito 2', 'Correlacion', 'Delito 1 Normalizado', 'Delito 2 Normalizado', 'Correlacion Normalizada'])\n",
    "df_cor.to_excel(f'correlaciones/{delegacion}.xlsx', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlación de delitos en CDMX por delegacion\n",
    "import seaborn as sns\n",
    "\n",
    "# función para crear matriz de correcilación\n",
    "def matriz_correlacion(delitos_count_norm):\n",
    "\tmatriz=[]\n",
    "\tfor delito in delitos_count_norm:\n",
    "\t\tfila=[]\n",
    "\t\tfor delito2 in delitos_count_norm:\n",
    "\t\t\tif delito==delito2:\n",
    "\t\t\t\tfila.append(0)\n",
    "\t\t\telse:\n",
    "\t\t\t\tfila.append(1/(abs(delito-delito2)+1))\n",
    "\t\tmatriz.append(fila)\n",
    "\treturn matriz\n",
    "\n",
    "\n",
    "df=df.dropna(subset=['delegacion_inicio'])\n",
    "# print(df['delegacion_inicio'].unique())\n",
    "for delegacion in df['delegacion_inicio'].unique():\n",
    "    # filtrar por delegacion\n",
    "    df_delegacion=df[df['delegacion_inicio']==delegacion]\n",
    "    # contar los delitos\n",
    "    delitos_count_norm=df_delegacion['incidente_c4'].value_counts()\n",
    "\n",
    "    # Normalización de datos, dónde 1 es el valor más alto\n",
    "    delitos_count_norm=delitos_count_norm/delitos_count_norm.max()\n",
    "\n",
    "    # crear una matriz de correlacion\n",
    "    matriz= matriz_correlacion(delitos_count_norm)\n",
    "    # graficar la matriz en un heatmap con los indices de los delitos\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.title(f'Correlacion entre delitos en {delegacion}', fontsize=30, fontweight='bold')\n",
    "    sns.heatmap(matriz, xticklabels=delitos_count_norm.index, yticklabels=delitos_count_norm.index, annot=True, cmap='Spectral_r')\n",
    "    plt.tick_params(axis='x', labelrotation=90, labeltop=True, labelbottom=False)\n",
    "    plt.show()\n",
    "\n",
    "    # Obtener los primeros 5 relaciones mas fuertes\n",
    "    relaciones = []\n",
    "    for i in range(len(matriz)):\n",
    "        for j in range(i,len(matriz[i])):\n",
    "            if i != j:\n",
    "                relaciones.append([delitos_count_norm.index[i], delitos_count_norm.index[j], matriz[i][j]])\n",
    "    relaciones.sort(key=lambda x: x[2], reverse=True)\n",
    "    print(f'Las 5 relaciones mas fuertes en {delegacion} son:')\n",
    "    for i in range(5):\n",
    "        print(f'{relaciones[i][0]} - {relaciones[i][1]}: {relaciones[i][2]}')\n",
    "    print()\n",
    "    #creatédirectory correlaciones\n",
    "    if not os.path.exists('correlaciones'):\n",
    "        os.makedirs('correlaciones')\n",
    "\n",
    "    #Save it in excel\n",
    "    import pandas as pd\n",
    "    df_cor = pd.DataFrame(relaciones[:5], columns = ['Delito 1', 'Delito 2', 'Correlacion'])\n",
    "    df_cor.to_excel(f'correlaciones/{delegacion}.xlsx', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis estádistico utilizando ARIMA\n",
    "\n",
    "#importar librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# To install statsmodels use conda install -c conda-forge statsmodels\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "# To install pmdarima use conda install -c conda-forge pmdarima\n",
    "from pmdarima import auto_arima \n",
    "\n",
    "df_by_delitos = df.groupby('incidente_c4')\n",
    "\n",
    "for delito, delito_df in df_by_delitos:\n",
    "\tprint('delito', delito)\n",
    "\n",
    "\tdelito_df_pt = delito_df.groupby('fecha_creacion').count()#['incidente_c4'].to_frame()\n",
    "\tdelito_df_pt.rename(columns={'incidente_c4':'obs'}, inplace=True)\n",
    "\tdelito_arima_df = delito_df_pt[['obs']]\n",
    "\tprint('delito_df_pt', delito_arima_df)\n",
    "\t#print('columns', delito_df_pt.columns)\n",
    "\n",
    "\t#find if one day is missing and print it\n",
    "\tfor i in range(len(delito_arima_df)-1):\n",
    "\t\tif delito_arima_df.index[i+1] - delito_arima_df.index[i] != pd.Timedelta(days=1):\n",
    "\t\t\tprint('Missing day', delito_arima_df.index[i+1])\n",
    "\t\t\t# add missing day\n",
    "\t\t\t\n",
    "\t\t\tdelito_arima_df.loc[delito_arima_df.index[i+1]] = 0\n",
    "\t\t\n",
    "\n",
    "\t# Create time series and plot\n",
    "\tRT = delito_arima_df.iloc[-678:].astype(float).squeeze().to_numpy()\n",
    "\tRT = pd.Series(RT, index=pd.date_range(start='2022-01-01', end='2022-12-31', freq='D'))\n",
    "\tplt.plot(RT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/lpenac/Documents/SUPERBASES/echo_TOTAL.Rds'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpmdarima\u001b[39;00m \u001b[39mimport\u001b[39;00m auto_arima \n\u001b[0;32m     11\u001b[0m \u001b[39m# Read RDS file\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m echoT \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_pickle(\u001b[39m\"\u001b[39;49m\u001b[39mC:/Users/lpenac/Documents/SUPERBASES/echo_TOTAL.Rds\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     14\u001b[0m \u001b[39m# Filter and group data\u001b[39;00m\n\u001b[0;32m     15\u001b[0m RoboTranseunte \u001b[39m=\u001b[39m (\n\u001b[0;32m     16\u001b[0m     echoT\u001b[39m.\u001b[39mloc[echoT[\u001b[39m'\u001b[39m\u001b[39mincidente_c4\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mRobo-Transeúnte\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     17\u001b[0m         \u001b[39m.\u001b[39mgroupby([\u001b[39m'\u001b[39m\u001b[39mfecha_cierre\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mincidente_c4\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[39m.\u001b[39mdrop(\u001b[39m'\u001b[39m\u001b[39mincidente_c4\u001b[39m\u001b[39m'\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     21\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\jddel\\miniconda3\\lib\\site-packages\\pandas\\io\\pickle.py:190\u001b[0m, in \u001b[0;36mread_pickle\u001b[1;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[39mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[39m4    4    9\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    189\u001b[0m excs_to_catch \u001b[39m=\u001b[39m (\u001b[39mAttributeError\u001b[39;00m, \u001b[39mImportError\u001b[39;00m, \u001b[39mModuleNotFoundError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m)\n\u001b[1;32m--> 190\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[0;32m    191\u001b[0m     filepath_or_buffer,\n\u001b[0;32m    192\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    193\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m    194\u001b[0m     is_text\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    195\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m    196\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[0;32m    197\u001b[0m \n\u001b[0;32m    198\u001b[0m     \u001b[39m# 1) try standard library Pickle\u001b[39;00m\n\u001b[0;32m    199\u001b[0m     \u001b[39m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[0;32m    200\u001b[0m     \u001b[39m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[0;32m    202\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    203\u001b[0m         \u001b[39m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[0;32m    204\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\jddel\\miniconda3\\lib\\site-packages\\pandas\\io\\common.py:865\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    861\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(handle, ioargs\u001b[39m.\u001b[39;49mmode)\n\u001b[0;32m    866\u001b[0m     handles\u001b[39m.\u001b[39mappend(handle)\n\u001b[0;32m    868\u001b[0m \u001b[39m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/lpenac/Documents/SUPERBASES/echo_TOTAL.Rds'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# To install statsmodels use conda install -c conda-forge statsmodels\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "# To install pmdarima use conda install -c conda-forge pmdarima\n",
    "from pmdarima import auto_arima \n",
    "\n",
    "# Read RDS file\n",
    "echoT = pd.read_pickle(\"C:/Users/lpenac/Documents/SUPERBASES/echo_TOTAL.Rds\")\n",
    "\n",
    "# Filter and group data\n",
    "RoboTranseunte = (\n",
    "    echoT.loc[echoT['incidente_c4'] == 'Robo-Transeúnte']\n",
    "        .groupby(['fecha_cierre', 'incidente_c4'])\n",
    "        .count()\n",
    "        .reset_index()\n",
    "        .drop('incidente_c4', axis=1)\n",
    ")\n",
    "\n",
    "# Create date range and join with grouped data\n",
    "date_range = pd.DataFrame({'fecha_cierre': pd.date_range(start='2021-01-01', end='2023-01-30', freq='D')})\n",
    "Rob = pd.merge(date_range, RoboTranseunte, on='fecha_cierre', how='left')\n",
    "Rob.fillna(0, inplace=True)\n",
    "Rob.rename(columns={'n': 'obs'}, inplace=True)\n",
    "Rob = Rob.drop('fecha_cierre', axis=1)\n",
    "\n",
    "# Create time series and plot\n",
    "RT = Rob.iloc[-678:].astype(float).squeeze().to_numpy()\n",
    "RT = pd.Series(RT, index=pd.date_range(start='2021-03-01', end='2023-01-30', freq='D'))\n",
    "plt.plot(RT)\n",
    "\n",
    "# ADF test\n",
    "result = adfuller(RT)\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])\n",
    "\n",
    "# Plot ACF and PACF\n",
    "plot_acf(RT, lags=365)\n",
    "plot_pacf(RT, lags=365)\n",
    "\n",
    "# Model 1\n",
    "model1 = ARIMA(RT, order=(1, 0, 1))\n",
    "model1 = model1.fit()\n",
    "print(model1.summary())\n",
    "residuals = model1.resid\n",
    "\n",
    "# Model 2\n",
    "model2 = ARIMA(RT, order=(7, 0, 7))\n",
    "model2 = model2.fit()\n",
    "print(model2.summary())\n",
    "residuals = model2.resid\n",
    "\n",
    "# Forecast with Model 2\n",
    "forecast = model2.forecast(steps=5)\n",
    "print(forecast)\n",
    "\n",
    "# Auto ARIMA\n",
    "auto = auto_arima(RT, seasonal=False, suppress_warnings=True)\n",
    "print(auto.summary())\n",
    "\n",
    "# Model 3\n",
    "model3 = ARIMA(RT, order=auto.order)\n",
    "model3 = model3.fit()\n",
    "print(model3.summary())\n",
    "residuals = model3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two points in crs epsg 4326, calculate their distance and if it is lower than 100mt print ok\n",
    "pt1 = [19.42059, -99.14724]\n",
    "pt2 = [19.41837, -99.14352]\n",
    "\n",
    "# calculate distance\n",
    "dist = geopy.distance.distance(pt1, pt2).m\n",
    "\n",
    "# print distance\n",
    "print(dist)\n",
    "\n",
    "# if distance is lower than 100mt print ok\n",
    "if dist < 100:\n",
    "    print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset \"BASE_24ENE023.xlsx\" with pandas\n",
    "import pandas as pd\n",
    "camaras_df_copy = pd.read_excel('BASE_24ENE023.xlsx', dtype=str, sheet_name='BASE') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "camaras_df = camaras_df_copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_BCT_O</th>\n",
       "      <th>LATITUD</th>\n",
       "      <th>LONGITUD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>19.435283</td>\n",
       "      <td>-99.147152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>19.435098</td>\n",
       "      <td>-99.14582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>19.434573</td>\n",
       "      <td>-99.143858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>19.434374</td>\n",
       "      <td>-99.142704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>19.434242</td>\n",
       "      <td>-99.14188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31318</th>\n",
       "      <td>MC18581</td>\n",
       "      <td>19.359499</td>\n",
       "      <td>-99.097748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31319</th>\n",
       "      <td>MC18749</td>\n",
       "      <td>19.445112</td>\n",
       "      <td>-99.123736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31320</th>\n",
       "      <td>MC17513</td>\n",
       "      <td>19.452434</td>\n",
       "      <td>-99.124443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31321</th>\n",
       "      <td>MC17609</td>\n",
       "      <td>19.435371</td>\n",
       "      <td>-99.119402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31322</th>\n",
       "      <td>MC17528</td>\n",
       "      <td>19.422815</td>\n",
       "      <td>-99.106361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31323 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID_BCT_O    LATITUD    LONGITUD\n",
       "0            1  19.435283  -99.147152\n",
       "1            2  19.435098   -99.14582\n",
       "2            3  19.434573  -99.143858\n",
       "3            4  19.434374  -99.142704\n",
       "4            5  19.434242   -99.14188\n",
       "...        ...        ...         ...\n",
       "31318  MC18581  19.359499  -99.097748\n",
       "31319  MC18749  19.445112  -99.123736\n",
       "31320  MC17513  19.452434  -99.124443\n",
       "31321  MC17609  19.435371  -99.119402\n",
       "31322  MC17528  19.422815  -99.106361\n",
       "\n",
       "[31323 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"ID_BCT_O,LATITUD,LONGITUD\"\"\"\n",
    "# dropear las columnas que sean diferentes a \"ID_BCT_O,LATITUD,LONGITUD\" de camaras_df\n",
    "camaras_df = camaras_df[['ID_BCT_O','LATITUD','LONGITUD']]\n",
    "camaras_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "461.55601385860615\n"
     ]
    }
   ],
   "source": [
    "import geopy.distance\n",
    "# to install geopy use \n",
    "# two points in crs epsg 4326, calculate their distance and if it is lower than 100mt print ok\n",
    "pt1 = [19.42059, -99.14724]\n",
    "pt2 = [19.41837, -99.14352]\n",
    "\n",
    "# calculate distance\n",
    "dist = geopy.distance.geodesic(pt1, pt2).m\n",
    "\n",
    "# print distance\n",
    "print(dist)\n",
    "\n",
    "# if distance is lower than 100mt print ok\n",
    "if dist < 100:\n",
    "    print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha_creacion</th>\n",
       "      <th>hora_creacion</th>\n",
       "      <th>mes_creacion</th>\n",
       "      <th>dia_creacion</th>\n",
       "      <th>semana_creacion</th>\n",
       "      <th>dia_semana</th>\n",
       "      <th>incidente_c4</th>\n",
       "      <th>delegacion_inicio</th>\n",
       "      <th>sector_inicio</th>\n",
       "      <th>latitud</th>\n",
       "      <th>longitud</th>\n",
       "      <th>codigo_cierre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-02</td>\n",
       "      <td>07:00</td>\n",
       "      <td>04-Abril</td>\n",
       "      <td>02</td>\n",
       "      <td>13</td>\n",
       "      <td>6-Sábado</td>\n",
       "      <td>Robo-Vehículo sin Violencia</td>\n",
       "      <td>GUSTAVO A. MADERO</td>\n",
       "      <td>CUAUTEPEC</td>\n",
       "      <td>19.540726</td>\n",
       "      <td>-99.1446619</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-04-07</td>\n",
       "      <td>22:00</td>\n",
       "      <td>04-Abril</td>\n",
       "      <td>07</td>\n",
       "      <td>14</td>\n",
       "      <td>4-Jueves</td>\n",
       "      <td>Robo-Vehiculo con Violencia</td>\n",
       "      <td>GUSTAVO A. MADERO</td>\n",
       "      <td>ARAGON</td>\n",
       "      <td>19.466062</td>\n",
       "      <td>-99.064584</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-04-07</td>\n",
       "      <td>21:00</td>\n",
       "      <td>04-Abril</td>\n",
       "      <td>07</td>\n",
       "      <td>14</td>\n",
       "      <td>4-Jueves</td>\n",
       "      <td>Robo-Vehiculo con Violencia</td>\n",
       "      <td>IZTAPALAPA</td>\n",
       "      <td>TEZONCO</td>\n",
       "      <td>19.294715</td>\n",
       "      <td>-99.065944</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-04-08</td>\n",
       "      <td>11:00</td>\n",
       "      <td>04-Abril</td>\n",
       "      <td>08</td>\n",
       "      <td>14</td>\n",
       "      <td>5-Viernes</td>\n",
       "      <td>Robo-Vehículo sin Violencia</td>\n",
       "      <td>TLALPAN</td>\n",
       "      <td>HUIPULCO-HOSPITALES</td>\n",
       "      <td>19.264921</td>\n",
       "      <td>-99.162166</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-04-15</td>\n",
       "      <td>21:00</td>\n",
       "      <td>04-Abril</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>5-Viernes</td>\n",
       "      <td>Agresión-Persona</td>\n",
       "      <td>CUAUHTEMOC</td>\n",
       "      <td>CENTRO</td>\n",
       "      <td>19.42481</td>\n",
       "      <td>-99.132952</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fecha_creacion hora_creacion mes_creacion dia_creacion  semana_creacion  \\\n",
       "0     2022-04-02         07:00     04-Abril           02               13   \n",
       "2     2022-04-07         22:00     04-Abril           07               14   \n",
       "3     2022-04-07         21:00     04-Abril           07               14   \n",
       "4     2022-04-08         11:00     04-Abril           08               14   \n",
       "6     2022-04-15         21:00     04-Abril           15               15   \n",
       "\n",
       "  dia_semana                 incidente_c4  delegacion_inicio  \\\n",
       "0   6-Sábado  Robo-Vehículo sin Violencia  GUSTAVO A. MADERO   \n",
       "2   4-Jueves  Robo-Vehiculo con Violencia  GUSTAVO A. MADERO   \n",
       "3   4-Jueves  Robo-Vehiculo con Violencia         IZTAPALAPA   \n",
       "4  5-Viernes  Robo-Vehículo sin Violencia            TLALPAN   \n",
       "6  5-Viernes             Agresión-Persona         CUAUHTEMOC   \n",
       "\n",
       "         sector_inicio    latitud     longitud codigo_cierre  \n",
       "0            CUAUTEPEC  19.540726  -99.1446619             A  \n",
       "2               ARAGON  19.466062   -99.064584             A  \n",
       "3              TEZONCO  19.294715   -99.065944             A  \n",
       "4  HUIPULCO-HOSPITALES  19.264921   -99.162166             A  \n",
       "6               CENTRO   19.42481   -99.132952             A  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropear colonia de df\n",
    "df = df.drop('colonia', axis=1)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camara: 1 <19.4352830000,-99.1471520000>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcamara: \u001b[39m\u001b[39m{\u001b[39;00mcam\u001b[39m.\u001b[39mID_BCT_O\u001b[39m}\u001b[39;00m\u001b[39m <\u001b[39m\u001b[39m{\u001b[39;00mcam\u001b[39m.\u001b[39mLATITUD\u001b[39m:\u001b[39;00m\u001b[39m.10f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m{\u001b[39;00mcam\u001b[39m.\u001b[39mLONGITUD\u001b[39m:\u001b[39;00m\u001b[39m.10f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m>\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     16\u001b[0m pt1 \u001b[39m=\u001b[39m [cam\u001b[39m.\u001b[39mLATITUD, cam\u001b[39m.\u001b[39mLONGITUD]\n\u001b[1;32m---> 18\u001b[0m geopy\u001b[39m.\u001b[39;49mdistance\u001b[39m.\u001b[39;49mgeodesic([pt1[\u001b[39m0\u001b[39;49m],\u001b[39m'\u001b[39;49m\u001b[39m0.0\u001b[39;49m\u001b[39m'\u001b[39;49m], [df[\u001b[39m'\u001b[39;49m\u001b[39mlatitud\u001b[39;49m\u001b[39m'\u001b[39;49m],\u001b[39m'\u001b[39;49m\u001b[39m0.0\u001b[39;49m\u001b[39m'\u001b[39;49m])\u001b[39m.\u001b[39mm\n\u001b[0;32m     20\u001b[0m \u001b[39m# Find the index of the lower limit of latitud\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[39m#latitud_lower_limit_index = df.iloc[geopy.distance.distance([pt1[0],'0.0'], [df['latitud'],'0.0']).meters < 100]\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39m#print(df[latitud_lower_limit_index])\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jddel\\miniconda3\\lib\\site-packages\\geopy\\distance.py:540\u001b[0m, in \u001b[0;36mgeodesic.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    538\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_ellipsoid(kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mellipsoid\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mWGS-84\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m    539\u001b[0m major, minor, f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mELLIPSOID\n\u001b[1;32m--> 540\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jddel\\miniconda3\\lib\\site-packages\\geopy\\distance.py:276\u001b[0m, in \u001b[0;36mDistance.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    275\u001b[0m     \u001b[39mfor\u001b[39;00m a, b \u001b[39min\u001b[39;00m util\u001b[39m.\u001b[39mpairwise(args):\n\u001b[1;32m--> 276\u001b[0m         kilometers \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmeasure(a, b)\n\u001b[0;32m    278\u001b[0m kilometers \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m units\u001b[39m.\u001b[39mkilometers(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    279\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__kilometers \u001b[39m=\u001b[39m kilometers\n",
      "File \u001b[1;32mc:\\Users\\jddel\\miniconda3\\lib\\site-packages\\geopy\\distance.py:556\u001b[0m, in \u001b[0;36mgeodesic.measure\u001b[1;34m(self, a, b)\u001b[0m\n\u001b[0;32m    555\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmeasure\u001b[39m(\u001b[39mself\u001b[39m, a, b):\n\u001b[1;32m--> 556\u001b[0m     a, b \u001b[39m=\u001b[39m Point(a), Point(b)\n\u001b[0;32m    557\u001b[0m     _ensure_same_altitude(a, b)\n\u001b[0;32m    558\u001b[0m     lat1, lon1 \u001b[39m=\u001b[39m a\u001b[39m.\u001b[39mlatitude, a\u001b[39m.\u001b[39mlongitude\n",
      "File \u001b[1;32mc:\\Users\\jddel\\miniconda3\\lib\\site-packages\\geopy\\point.py:175\u001b[0m, in \u001b[0;36mPoint.__new__\u001b[1;34m(cls, latitude, longitude, altitude)\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    172\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mFailed to create Point instance from \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg,)\n\u001b[0;32m    173\u001b[0m             )\n\u001b[0;32m    174\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 175\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mfrom_sequence(seq)\n\u001b[0;32m    177\u001b[0m \u001b[39mif\u001b[39;00m single_arg:\n\u001b[0;32m    178\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    179\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mA single number has been passed to the Point \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    180\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mconstructor. This is probably a mistake, because \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    184\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mto get rid of this error.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    185\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jddel\\miniconda3\\lib\\site-packages\\geopy\\point.py:472\u001b[0m, in \u001b[0;36mPoint.from_sequence\u001b[1;34m(cls, seq)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[0;32m    470\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mWhen creating a Point from sequence, it \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    471\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39mmust not have more than 3 items.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 472\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[1;32mc:\\Users\\jddel\\miniconda3\\lib\\site-packages\\geopy\\point.py:188\u001b[0m, in \u001b[0;36mPoint.__new__\u001b[1;34m(cls, latitude, longitude, altitude)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[39mif\u001b[39;00m single_arg:\n\u001b[0;32m    178\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    179\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mA single number has been passed to the Point \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    180\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mconstructor. This is probably a mistake, because \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    184\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mto get rid of this error.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    185\u001b[0m     )\n\u001b[0;32m    187\u001b[0m latitude, longitude, altitude \u001b[39m=\u001b[39m \\\n\u001b[1;32m--> 188\u001b[0m     _normalize_coordinates(latitude, longitude, altitude)\n\u001b[0;32m    190\u001b[0m \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__new__\u001b[39m(\u001b[39mcls\u001b[39m)\n\u001b[0;32m    191\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlatitude \u001b[39m=\u001b[39m latitude\n",
      "File \u001b[1;32mc:\\Users\\jddel\\miniconda3\\lib\\site-packages\\geopy\\point.py:57\u001b[0m, in \u001b[0;36m_normalize_coordinates\u001b[1;34m(latitude, longitude, altitude)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_normalize_coordinates\u001b[39m(latitude, longitude, altitude):\n\u001b[1;32m---> 57\u001b[0m     latitude \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(latitude \u001b[39mor\u001b[39;00m \u001b[39m0.0\u001b[39m)\n\u001b[0;32m     58\u001b[0m     longitude \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(longitude \u001b[39mor\u001b[39;00m \u001b[39m0.0\u001b[39m)\n\u001b[0;32m     59\u001b[0m     altitude \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(altitude \u001b[39mor\u001b[39;00m \u001b[39m0.0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jddel\\miniconda3\\lib\\site-packages\\pandas\\core\\generic.py:1527\u001b[0m, in \u001b[0;36mNDFrame.__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[0;32m   1526\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__nonzero__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NoReturn:\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1528\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe truth value of a \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m is ambiguous. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1529\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUse a.empty, a.bool(), a.item(), a.any() or a.all().\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1530\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "import geopy\n",
    "import geopy.distance\n",
    "# To df order by latitud and longitud\n",
    "df = df.sort_values(by=['latitud', 'longitud'])\n",
    "df.latitud = df.latitud.astype(float)\n",
    "df.longitud = df.longitud.astype(float)\n",
    "\n",
    "#Parse camaras_df.LATITUD and cam.LONGITUD to float\n",
    "camaras_df.LATITUD = camaras_df.LATITUD.astype(float)\n",
    "camaras_df.LONGITUD = camaras_df.LONGITUD.astype(float)\n",
    "\n",
    "# Find lower limit and upper limit of latitud and longitud where distance with each camera is lower than 100mt\n",
    "for cam in camaras_df[:1].itertuples():\n",
    "\t# print(cam)\n",
    "\tprint(f'camara: {cam.ID_BCT_O} <{cam.LATITUD:.10f},{cam.LONGITUD:.10f}>')\n",
    "\tpt1 = [cam.LATITUD, cam.LONGITUD]\n",
    "\n",
    "\tgeopy.distance.geodesic([pt1[0],'0.0'], [df['latitud'],'0.0']).m\n",
    "\n",
    "\t# Find the index of the lower limit of latitud\n",
    "\t#latitud_lower_limit_index = df.iloc[geopy.distance.distance([pt1[0],'0.0'], [df['latitud'],'0.0']).meters < 100]\n",
    "\t#print(df[latitud_lower_limit_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 %\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jddel\\miniconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1219\u001b[0m, in \u001b[0;36mmaybe_infer_to_datetimelike.<locals>.try_datetime\u001b[1;34m(v)\u001b[0m\n\u001b[0;32m   1216\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1217\u001b[0m     \u001b[39m# GH#19671 we pass require_iso8601 to be relatively strict\u001b[39;00m\n\u001b[0;32m   1218\u001b[0m     \u001b[39m#  when parsing strings.\u001b[39;00m\n\u001b[1;32m-> 1219\u001b[0m     dta \u001b[39m=\u001b[39m sequence_to_datetimes(v, require_iso8601\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m   1220\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[0;32m   1221\u001b[0m     \u001b[39m# e.g. <class 'numpy.timedelta64'> is not convertible to datetime\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jddel\\miniconda3\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:1969\u001b[0m, in \u001b[0;36msequence_to_datetimes\u001b[1;34m(data, require_iso8601)\u001b[0m\n\u001b[0;32m   1966\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1967\u001b[0m \u001b[39mParse/convert the passed data to either DatetimeArray or np.ndarray[object].\u001b[39;00m\n\u001b[0;32m   1968\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1969\u001b[0m result, tz, freq \u001b[39m=\u001b[39m _sequence_to_dt64ns(\n\u001b[0;32m   1970\u001b[0m     data,\n\u001b[0;32m   1971\u001b[0m     allow_mixed\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1972\u001b[0m     require_iso8601\u001b[39m=\u001b[39;49mrequire_iso8601,\n\u001b[0;32m   1973\u001b[0m )\n\u001b[0;32m   1975\u001b[0m dtype \u001b[39m=\u001b[39m tz_to_dtype(tz)\n",
      "File \u001b[1;32mc:\\Users\\jddel\\miniconda3\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:2054\u001b[0m, in \u001b[0;36m_sequence_to_dt64ns\u001b[1;34m(data, dtype, copy, tz, dayfirst, yearfirst, ambiguous, allow_mixed, require_iso8601)\u001b[0m\n\u001b[0;32m   2051\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2052\u001b[0m     \u001b[39m# data comes back here as either i8 to denote UTC timestamps\u001b[39;00m\n\u001b[0;32m   2053\u001b[0m     \u001b[39m#  or M8[ns] to denote wall times\u001b[39;00m\n\u001b[1;32m-> 2054\u001b[0m     data, inferred_tz \u001b[39m=\u001b[39m objects_to_datetime64ns(\n\u001b[0;32m   2055\u001b[0m         data,\n\u001b[0;32m   2056\u001b[0m         dayfirst\u001b[39m=\u001b[39;49mdayfirst,\n\u001b[0;32m   2057\u001b[0m         yearfirst\u001b[39m=\u001b[39;49myearfirst,\n\u001b[0;32m   2058\u001b[0m         allow_object\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   2059\u001b[0m         allow_mixed\u001b[39m=\u001b[39;49mallow_mixed,\n\u001b[0;32m   2060\u001b[0m         require_iso8601\u001b[39m=\u001b[39;49mrequire_iso8601,\n\u001b[0;32m   2061\u001b[0m     )\n\u001b[0;32m   2062\u001b[0m     \u001b[39mif\u001b[39;00m tz \u001b[39mand\u001b[39;00m inferred_tz:\n\u001b[0;32m   2063\u001b[0m         \u001b[39m#  two timezones: convert to intended from base UTC repr\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jddel\\miniconda3\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:2177\u001b[0m, in \u001b[0;36mobjects_to_datetime64ns\u001b[1;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object, allow_mixed)\u001b[0m\n\u001b[0;32m   2176\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 2177\u001b[0m     result, tz_parsed \u001b[39m=\u001b[39m tslib\u001b[39m.\u001b[39;49marray_to_datetime(\n\u001b[0;32m   2178\u001b[0m         data\u001b[39m.\u001b[39;49mravel(\u001b[39m\"\u001b[39;49m\u001b[39mK\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   2179\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   2180\u001b[0m         utc\u001b[39m=\u001b[39;49mutc,\n\u001b[0;32m   2181\u001b[0m         dayfirst\u001b[39m=\u001b[39;49mdayfirst,\n\u001b[0;32m   2182\u001b[0m         yearfirst\u001b[39m=\u001b[39;49myearfirst,\n\u001b[0;32m   2183\u001b[0m         require_iso8601\u001b[39m=\u001b[39;49mrequire_iso8601,\n\u001b[0;32m   2184\u001b[0m         allow_mixed\u001b[39m=\u001b[39;49mallow_mixed,\n\u001b[0;32m   2185\u001b[0m     )\n\u001b[0;32m   2186\u001b[0m     result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39mreshape(data\u001b[39m.\u001b[39mshape, order\u001b[39m=\u001b[39morder)\n",
      "File \u001b[1;32mc:\\Users\\jddel\\miniconda3\\lib\\site-packages\\pandas\\_libs\\tslib.pyx:427\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\jddel\\miniconda3\\lib\\site-packages\\pandas\\_libs\\tslib.pyx:599\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: time data \"15:00\" at position 1 doesn't match format specified",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m center \u001b[39m=\u001b[39m (lat1, lon1) \u001b[39m# latitud y longitud del punto central\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[39m# obtener la latitud y longitud de cada registro de df en una lista\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m points \u001b[39m=\u001b[39m [(row[\u001b[39m'\u001b[39m\u001b[39mlatitud\u001b[39m\u001b[39m'\u001b[39m], row[\u001b[39m'\u001b[39m\u001b[39mlongitud\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39mfor\u001b[39;00m index, row \u001b[39min\u001b[39;00m df\u001b[39m.\u001b[39miterrows()]\n\u001b[0;32m     13\u001b[0m radius \u001b[39m=\u001b[39m \u001b[39m50\u001b[39m \u001b[39m# radio en metros\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m# Calcular la distancia entre el punto central y cada punto\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[15], line 11\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      9\u001b[0m center \u001b[39m=\u001b[39m (lat1, lon1) \u001b[39m# latitud y longitud del punto central\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[39m# obtener la latitud y longitud de cada registro de df en una lista\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m points \u001b[39m=\u001b[39m [(row[\u001b[39m'\u001b[39m\u001b[39mlatitud\u001b[39m\u001b[39m'\u001b[39m], row[\u001b[39m'\u001b[39m\u001b[39mlongitud\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39mfor\u001b[39;00m index, row \u001b[39min\u001b[39;00m df\u001b[39m.\u001b[39miterrows()]\n\u001b[0;32m     13\u001b[0m radius \u001b[39m=\u001b[39m \u001b[39m50\u001b[39m \u001b[39m# radio en metros\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m# Calcular la distancia entre el punto central y cada punto\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jddel\\miniconda3\\lib\\site-packages\\pandas\\core\\frame.py:1411\u001b[0m, in \u001b[0;36mDataFrame.iterrows\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1409\u001b[0m klass \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor_sliced\n\u001b[0;32m   1410\u001b[0m \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues):\n\u001b[1;32m-> 1411\u001b[0m     s \u001b[39m=\u001b[39m klass(v, index\u001b[39m=\u001b[39;49mcolumns, name\u001b[39m=\u001b[39;49mk)\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m)\n\u001b[0;32m   1412\u001b[0m     \u001b[39myield\u001b[39;00m k, s\n",
      "File \u001b[1;32mc:\\Users\\jddel\\miniconda3\\lib\\site-packages\\pandas\\core\\series.py:470\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    468\u001b[0m         data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m    469\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 470\u001b[0m     data \u001b[39m=\u001b[39m sanitize_array(data, index, dtype, copy)\n\u001b[0;32m    472\u001b[0m     manager \u001b[39m=\u001b[39m get_option(\u001b[39m\"\u001b[39m\u001b[39mmode.data_manager\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    473\u001b[0m     \u001b[39mif\u001b[39;00m manager \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mblock\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\jddel\\miniconda3\\lib\\site-packages\\pandas\\core\\construction.py:597\u001b[0m, in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, raise_cast_failure, allow_2d)\u001b[0m\n\u001b[0;32m    594\u001b[0m             subarr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(data, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m    595\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    596\u001b[0m         \u001b[39m# we will try to copy by-definition here\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m         subarr \u001b[39m=\u001b[39m _try_cast(data, dtype, copy, raise_cast_failure)\n\u001b[0;32m    599\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ABCExtensionArray):\n\u001b[0;32m    600\u001b[0m     \u001b[39m# it is already ensured above this is not a PandasArray\u001b[39;00m\n\u001b[0;32m    601\u001b[0m     subarr \u001b[39m=\u001b[39m data\n",
      "File \u001b[1;32mc:\\Users\\jddel\\miniconda3\\lib\\site-packages\\pandas\\core\\construction.py:777\u001b[0m, in \u001b[0;36m_try_cast\u001b[1;34m(arr, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[0;32m    774\u001b[0m \u001b[39mif\u001b[39;00m arr\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m \u001b[39mobject\u001b[39m:\n\u001b[0;32m    775\u001b[0m     \u001b[39mreturn\u001b[39;00m sanitize_to_nanoseconds(arr, copy\u001b[39m=\u001b[39mcopy)\n\u001b[1;32m--> 777\u001b[0m out \u001b[39m=\u001b[39m maybe_infer_to_datetimelike(arr)\n\u001b[0;32m    778\u001b[0m \u001b[39mif\u001b[39;00m out \u001b[39mis\u001b[39;00m arr \u001b[39mand\u001b[39;00m copy:\n\u001b[0;32m    779\u001b[0m     out \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mcopy()\n",
      "File \u001b[1;32mc:\\Users\\jddel\\miniconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1255\u001b[0m, in \u001b[0;36mmaybe_infer_to_datetimelike\u001b[1;34m(value)\u001b[0m\n\u001b[0;32m   1248\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39mmaybe_convert_objects(  \u001b[39m# type: ignore[return-value]\u001b[39;00m\n\u001b[0;32m   1249\u001b[0m         v, convert_period\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, convert_interval\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m     )\n\u001b[0;32m   1252\u001b[0m \u001b[39mif\u001b[39;00m inferred_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdatetime\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1253\u001b[0m     \u001b[39m# error: Incompatible types in assignment (expression has type \"ExtensionArray\",\u001b[39;00m\n\u001b[0;32m   1254\u001b[0m     \u001b[39m# variable has type \"Union[ndarray, List[Any]]\")\u001b[39;00m\n\u001b[1;32m-> 1255\u001b[0m     value \u001b[39m=\u001b[39m try_datetime(v)  \u001b[39m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m   1256\u001b[0m \u001b[39melif\u001b[39;00m inferred_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtimedelta\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1257\u001b[0m     value \u001b[39m=\u001b[39m try_timedelta(v)\n",
      "File \u001b[1;32mc:\\Users\\jddel\\miniconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1219\u001b[0m, in \u001b[0;36mmaybe_infer_to_datetimelike.<locals>.try_datetime\u001b[1;34m(v)\u001b[0m\n\u001b[0;32m   1214\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39marrays\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatetimes\u001b[39;00m \u001b[39mimport\u001b[39;00m sequence_to_datetimes\n\u001b[0;32m   1216\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1217\u001b[0m     \u001b[39m# GH#19671 we pass require_iso8601 to be relatively strict\u001b[39;00m\n\u001b[0;32m   1218\u001b[0m     \u001b[39m#  when parsing strings.\u001b[39;00m\n\u001b[1;32m-> 1219\u001b[0m     dta \u001b[39m=\u001b[39m sequence_to_datetimes(v, require_iso8601\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m   1220\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[0;32m   1221\u001b[0m     \u001b[39m# e.g. <class 'numpy.timedelta64'> is not convertible to datetime\u001b[39;00m\n\u001b[0;32m   1222\u001b[0m     \u001b[39mreturn\u001b[39;00m v\u001b[39m.\u001b[39mreshape(shape)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from geopy import distance\n",
    "# obtener latitud y longitud de cada registro de camaras_df\n",
    "for index, row in camaras_df.iterrows():\n",
    "    print(index/len(camaras_df),\"%\", end=\"\\r\")\n",
    "    lat1 = row['LATITUD']\n",
    "    lon1 = row['LONGITUD']\n",
    "    # obtener latitud y longitud de cada registro de df\n",
    "        \n",
    "    center = (lat1, lon1) # latitud y longitud del punto central\n",
    "    # obtener la latitud y longitud de cada registro de df en una lista\n",
    "    points = [(row['latitud'], row['longitud']) for index, row in df.iterrows()]\n",
    "\n",
    "    radius = 50 # radio en metros\n",
    "\n",
    "    # Calcular la distancia entre el punto central y cada punto\n",
    "    distances = [distance.distance(center, point).m for point in points]\n",
    "\n",
    "    # Filtrar los puntos dentro del radio\n",
    "    within_radius = [point for point, dist in zip(points, distances) if dist <= radius]\n",
    "\n",
    "    # crear una nueva matriz llamada puntos_etiquetados\n",
    "    puntos_etiquetados = []\n",
    "    \n",
    "    # guardar en \"puntos_etiquetados\" todos los puntos dentro del radio copiar la informacion de todas las columnas de df y añadir una columna con el id de la camara\n",
    "    for point in within_radius:\n",
    "        punto = df.loc[(df['latitud'] == point[0]) & (df['longitud'] == point[1])]\n",
    "        punto['id_camara'] = row['ID_BCT_O']\n",
    "        puntos_etiquetados.append(punto)\n",
    "\n",
    "puntos_etiquetados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "def process_camaras(row):\n",
    "    \n",
    "    lat1 = row['LATITUD']\n",
    "    lon1 = row['LONGITUD']\n",
    "    center = (lat1, lon1) # latitud y longitud del punto central\n",
    "    # obtener la latitud y longitud de cada registro de df en una lista\n",
    "    # convert next line in loop cycle\n",
    "    points = [(row['latitud'], row['longitud']) for index, row in df.iterrows()]\n",
    "    print(\":)\", end=' ')\n",
    "\n",
    "    radius = 50 # radio en metros\n",
    "\n",
    "    # Calcular la distancia entre el punto central y cada punto\n",
    "    distances = [distance.distance(center, point).m for point in points]\n",
    "\n",
    "    # Filtrar los puntos dentro del radio\n",
    "    within_radius = [point for point, dist in zip(points, distances) if dist <= radius]\n",
    "\n",
    "    puntos_etiquetados = []\n",
    "    for point in within_radius:\n",
    "        punto = df.loc[(df['latitud'] == point[0]) & (df['longitud'] == point[1])]\n",
    "        punto['id_camara'] = row['ID_BCT_O']\n",
    "        puntos_etiquetados.append(punto)\n",
    "\n",
    "    return puntos_etiquetados\n",
    "\n",
    "# crear una lista de argumentos para pasar a cada proceso\n",
    "arguments = [(index, row) for index, row in camaras_df.iterrows()]\n",
    "\n",
    "# iniciar los procesos y esperar a que terminen\n",
    "with mp.Pool(processes=mp.cpu_count()) as pool:\n",
    "    puntos_etiquetados = pool.starmap(process_camaras, arguments)\n",
    "\n",
    "# concatenar los resultados en una sola DataFrame\n",
    "puntos_etiquetados = pd.concat(puntos_etiquetados)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "c5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 24 2022, 14:07:00) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31e69716cb25b15e196e36d862dc16f39614362d788ece2c262143c2e716c36f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
