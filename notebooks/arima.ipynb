{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pmdarima.arima import auto_arima, ADFTest\n",
    "from sklearn.metrics import classification_report, mean_absolute_error, mean_squared_error\n",
    "from mutil import *\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar los datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delitos, df_camaras = load_data()\n",
    "df_delitos = preprocess_data(df_delitos, df_camaras)\n",
    "\n",
    "#find out the most common crime\n",
    "delitos = df_delitos['incidente_c4'].value_counts().sort_values(ascending=False)\n",
    "# get the most common crime\n",
    "delito = delitos.index[0]\n",
    "most_common_crime = delito\n",
    "print('Most common crime: ', most_common_crime)\n",
    "delitos.plot(kind='bar', title='Delitos')\n",
    "plt.show()\n",
    "\n",
    "# Filter df_delitos by most common crime\n",
    "df_delitos = df_delitos[df_delitos['incidente_c4'] == most_common_crime]\n",
    "columns = list(df_delitos.columns)\n",
    "# Drop columns called [latitud, longitud, folio, incidente_c4]from columns\n",
    "columns = [x for x in columns if x not in ['latitud', 'longitud', 'folio', 'incidente_c4', 'colonia', 'sector_inicio']]\n",
    "\n",
    "# Set 00 the minutes and second from the hour in the column fecha_creacion and convert to datetime\n",
    "df_delitos['fecha_creacion'] = df_delitos['fecha_creacion'].dt.strftime('%Y-%m-%d %H:00:00')\n",
    "df_delitos['fecha_creacion'] = pd.to_datetime(df_delitos['fecha_creacion'], format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delitos = df_delitos.groupby('id_camara')\n",
    "df_delitos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"# Find group with most data\n",
    "# max_len = 0\n",
    "# max_id = 0\n",
    "# for id_camara, df in df_delitos:\n",
    "# \tif len(df) > max_len:\n",
    "# \t\tmax_len = len(df)\n",
    "# \t\tmax_id = id_camara\n",
    "\n",
    "# print(max_id, max_len) \n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get group by '1'\n",
    "# df_delitos = df_delitos.get_group('MC3857')\n",
    "# print(len(df_delitos))\n",
    "# df_delitos.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"#split the data into train (whole dates in 2022) and test (whole dates in 2023)\n",
    "# train = df_delitos[df_delitos.fecha_creacion.dt.year == 2022]\n",
    "# test = df_delitos[df_delitos.fecha_creacion.dt.year == 2023]\n",
    "\n",
    "# # Count the number of crimes per day but saving the date and the id_camara\n",
    "# df_delitos_train_count = train.groupby(['id_camara', 'fecha_creacion']).size().reset_index(name='count')\n",
    "# df_delitos_test_count = test.groupby(['id_camara', 'fecha_creacion']).size().reset_index(name='count')\n",
    "\n",
    "# # recorre df_delitos_train_count por los 365 dias del año 2022, donde no hay datos, los rellena con 0 en count\n",
    "# df_delitos_train_count = df_delitos_train_count.set_index('fecha_creacion').reindex(pd.date_range(start='2022-01-01', end='2022-12-31')).reset_index().rename(columns={'index': 'fecha_creacion'})\n",
    "# df_delitos_train_count['count'] = df_delitos_train_count['count'].fillna(0)\n",
    "\n",
    "# # recorre df_delitos_test_count por los 365 dias del año 2023, donde no hay datos, los rellena con 0 en count\n",
    "# df_delitos_test_count = df_delitos_test_count.set_index('fecha_creacion').reindex(pd.date_range(start='2023-01-01', end='2023-01-31')).reset_index().rename(columns={'index': 'fecha_creacion'})\n",
    "# df_delitos_test_count['count'] = df_delitos_test_count['count'].fillna(0)\n",
    "\n",
    "# print(f'Number of observations in train: {len(df_delitos_train_count)} ({(len(df_delitos_train_count)*100/len(df_delitos)):.2f})%')\n",
    "# print(f'Number of observations in test: {len(df_delitos_test_count)} ({(len(df_delitos_test_count)*100/len(df_delitos)):.2f})%')\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delitos_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delitos_count.fecha_creacion[df_delitos_count.index.duplicated()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 91/23953 ID:10097 lunes>0:00..."
     ]
    }
   ],
   "source": [
    "# Análisis estádistico utilizando auto ARIMA\n",
    "\n",
    "# save the minumum error and best error \n",
    "i = 0\n",
    "min_value = math.inf\n",
    "max_value = -math.inf\n",
    "dayofweek = {0: 'lunes', 1: 'martes', 2: 'miércoles', 3: 'jueves', 4: 'viernes', 5: 'sábado', 6: 'domingo'}\n",
    "\n",
    "# Iteration for each hour and day of the week\n",
    "for day in range(0, 7):\n",
    "\t# dictionary with the day of the week in spanish\n",
    "\t# day name in spanish\n",
    "\tday_name = dayofweek[day]\n",
    "\t# Save next results where there is data for the day of the week in a excel called 'consigas_[dayofweek].csv' with the columns: STV:id_camara, hora:hour_start:00-hour_start:59, dia:dayofweek\n",
    "\t# create a dataframe with the columns: STV:id_camara, hora:hour_start:00-hour_start:59, dia:dayofweek\n",
    "\tdf_delitos_count_day = pd.DataFrame(columns=['STV', 'hora', 'dia'])\n",
    "\tfor hour in range(0, 24):\n",
    "\t\tfor id_camara, df in df_delitos:\n",
    "\t\t\ti += 1\n",
    "\t\t\tprint(f'\\rProcessing {i}/{len(df_delitos.groups)} ID:{id_camara} {day_name}>{hour}:00...', end='')\n",
    "\t\t\t# print(f'Processing {i}/{len(df_delitos.groups)} ID:{id_camara}...')\n",
    "\t\t\t# Count the number of crimes per day but saving the date and the id_camara and set the fecha_creacion as index\n",
    "\t\t\tdf_delitos_count = df.groupby(columns).size().reset_index(name='count')\n",
    "\t\t\t#print(df_delitos_count.head())\n",
    "\t\t\t# Create rows for all the hours in the year 2022 and 2023 without losing the existing data\n",
    "\t\t\tdf_delitos_count = df_delitos_count.set_index('fecha_creacion').reindex(pd.date_range(start='2022-01-01', end='2023-02-01', freq='H')).reset_index().rename(columns={'index': 'fecha_creacion'})\n",
    "\t\t\t# Find not nat values\n",
    "\t\t\tdf_delitos_count.fillna(0, inplace=True)\n",
    "\t\t\t# Split the data into train (last 3 months in 2022) and test (first 2 weeks in 2023)\n",
    "\t\t\t# DONT USE 'train = df_delitos_count[df_delitos_count.fecha_creacion.dt.year == 2022 and df_delitos_count.fecha_creacion.dt.month >= 10]' IS AMBIGUOUS\n",
    "\t\t\ttrain = df_delitos_count[(df_delitos_count.fecha_creacion.dt.year == 2022) | (df_delitos_count.fecha_creacion.dt.isocalendar().week >= 52)]\n",
    "\t\t\ttest = df_delitos_count[(df_delitos_count.fecha_creacion.dt.year == 2023) & (df_delitos_count.fecha_creacion.dt.isocalendar().week == 1)]\n",
    "\t\t\t# Hacer autoarima como en la seccion de abajo para todos los lunes a las 00:00, despues todos los lunes a las 01:00, etc\n",
    "\t\t\t# Filter the data for the hour and day of the week\n",
    "\t\t\ttrain_hour = train[(train.fecha_creacion.dt.hour == hour) & (train.fecha_creacion.dt.dayofweek == day)]\n",
    "\t\t\ttest_hour = test[(test.fecha_creacion.dt.hour == hour) & (test.fecha_creacion.dt.dayofweek == day)]\n",
    "\t\t\t# If there is no data for the hour and day of the week, continue\n",
    "\t\t\tif len(train_hour) == 0 or len(test_hour) == 0:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t# Fit the model\t\t\t\n",
    "\t\t\tmodel = auto_arima(train['count'], stationary=True, \n",
    "\t\t\t\t\t\t\t\t\ttest='adf', start_p=1, d=1, start_q=0,\n",
    "\t\t\t\t\t\t\t\t\tmax_p=7, max_d=7, max_q=7,\n",
    "\t\t\t\t\t\t\t\t\t# daily data \n",
    "\t\t\t\t\t\t\t\t\tm=0,\n",
    "\t\t\t\t\t\t\t\t\t# Desactivar el test\n",
    "\t\t\t\t\t\t\t\t\t# seasonal=False,\n",
    "\t\t\t\t\t\t\t\t\tseasonal=False,\n",
    "\t\t\t\t\t\t\t\t\tseasonal_test='ch', start_P=0, D=0, start_Q=0,\n",
    "\t\t\t\t\t\t\t\t\ttrace=False, stepwise=True,\n",
    "\t\t\t\t\t\t\t\t\tsuppress_warnings=True, error_action='ignore',\n",
    "\t\t\t\t\t\t\t\t\trandom_state=0)\n",
    "\t\t\t# Forecast\n",
    "\t\t\tforecast, confint = model.predict(n_periods=len(test_hour), return_conf_int=True)\n",
    "\t\t\t# day as string name\n",
    "\t\t\t# Save the results from the forecast\n",
    "\t\t\tdf_delitos_count_day = pd.concat([df_delitos_count_day, pd.DataFrame({'STV': id_camara, 'hora': f'{hour}:00-{hour}:59', 'dia': day_name, 'cantidad': forecast})], ignore_index=True)\n",
    "\t#Drop rows tih cantidad = 0\n",
    "\tdf_delitos_count_day = df_delitos_count_day[df_delitos_count_day['cantidad'] != 0]\n",
    "\t# Order the columns by dia, hora and STV\n",
    "\tdf_delitos_count_day.sort_values(by=['dia', 'hora', 'STV'], inplace=True)\n",
    "\t# Save the results from the forecast\n",
    "\tdf_delitos_count_day.to_csv(f'consigas_{day_name}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis estádistico utilizando ARIMA\n",
    "\n",
    "# To install statsmodels use conda install -c conda-forge statsmodels\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "# To install pmdarima use conda install -c conda-forge pmdarima\n",
    "from pmdarima import auto_arima \n",
    "\n",
    "df_by_delitos = df.groupby('incidente_c4')\n",
    "\n",
    "for delito, delito_df in df_by_delitos:\n",
    "\tprint('delito', delito)\n",
    "\n",
    "\tdelito_df_pt = delito_df.groupby('fecha_creacion').count()#['incidente_c4'].to_frame()\n",
    "\tdelito_df_pt.rename(columns={'incidente_c4':'obs'}, inplace=True)\n",
    "\tdelito_arima_df = delito_df_pt[['obs']]\n",
    "\tprint('delito_df_pt', delito_arima_df)\n",
    "\t#print('columns', delito_df_pt.columns)\n",
    "\n",
    "\t#find if one day is missing and print it\n",
    "\tfor i in range(len(delito_arima_df)-1):\n",
    "\t\tif delito_arima_df.index[i+1] - delito_arima_df.index[i] != pd.Timedelta(days=1):\n",
    "\t\t\tprint('Missing day', delito_arima_df.index[i+1])\n",
    "\t\t\t# add missing day\n",
    "\t\t\t\n",
    "\t\t\tdelito_arima_df.loc[delito_arima_df.index[i+1]] = 0\n",
    "\t\n",
    "\t# Create time series and plot\n",
    "\tRT = delito_arima_df.iloc[-678:].astype(float).squeeze().to_numpy()\n",
    "\tRT = pd.Series(RT, index=pd.date_range(start='2022-01-01', end='2022-12-31', freq='D'))\n",
    "\tplt.plot(RT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To install statsmodels use conda install -c conda-forge statsmodels\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "# To install pmdarima use conda install -c conda-forge pmdarima\n",
    "from pmdarima import auto_arima \n",
    "\n",
    "# Read RDS file\n",
    "echoT = pd.read_pickle(\"C:/Users/lpenac/Documents/SUPERBASES/echo_TOTAL.Rds\")\n",
    "\n",
    "# Filter and group data\n",
    "RoboTranseunte = (\n",
    "\techoT.loc[echoT['incidente_c4'] == 'Robo-Transeúnte']\n",
    "\t\t.groupby(['fecha_cierre', 'incidente_c4'])\n",
    "\t\t.count()\n",
    "\t\t.reset_index()\n",
    "\t\t.drop('incidente_c4', axis=1)\n",
    ")\n",
    "\n",
    "# Create date range and join with grouped data\n",
    "date_range = pd.DataFrame({'fecha_cierre': pd.date_range(start='2021-01-01', end='2023-01-30', freq='D')})\n",
    "Rob = pd.merge(date_range, RoboTranseunte, on='fecha_cierre', how='left')\n",
    "Rob.fillna(0, inplace=True)\n",
    "Rob.rename(columns={'n': 'obs'}, inplace=True)\n",
    "Rob = Rob.drop('fecha_cierre', axis=1)\n",
    "\n",
    "# Create time series and plot\n",
    "RT = Rob.iloc[-678:].astype(float).squeeze().to_numpy()\n",
    "RT = pd.Series(RT, index=pd.date_range(start='2021-03-01', end='2023-01-30', freq='D'))\n",
    "plt.plot(RT)\n",
    "\n",
    "# ADF test\n",
    "result = adfuller(RT)\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])\n",
    "\n",
    "# Plot ACF and PACF\n",
    "plot_acf(RT, lags=365)\n",
    "plot_pacf(RT, lags=365)\n",
    "\n",
    "# Model 1\n",
    "model1 = ARIMA(RT, order=(1, 0, 1))\n",
    "model1 = model1.fit()\n",
    "print(model1.summary())\n",
    "residuals = model1.resid\n",
    "\n",
    "# Model 2\n",
    "model2 = ARIMA(RT, order=(7, 0, 7))\n",
    "model2 = model2.fit()\n",
    "print(model2.summary())\n",
    "residuals = model2.resid\n",
    "\n",
    "# Forecast with Model 2\n",
    "forecast = model2.forecast(steps=5)\n",
    "print(forecast)\n",
    "\n",
    "# Auto ARIMA\n",
    "auto = auto_arima(RT, seasonal=False, suppress_warnings=True)\n",
    "print(auto.summary())\n",
    "\n",
    "# Model 3\n",
    "model3 = ARIMA(RT, order=auto.order)\n",
    "model3 = model3.fit()\n",
    "print(model3.summary())\n",
    "residuals = model3\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "c5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31e69716cb25b15e196e36d862dc16f39614362d788ece2c262143c2e716c36f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
